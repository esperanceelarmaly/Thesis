{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPNKeWMrnEpP",
        "outputId": "878507c6-a4b4-488c-b3e4-3b30f8ed1804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount the Google Drive to Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kO2lPFsA72o2"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import os, random, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vtl8wOXZ0_jV"
      },
      "outputs": [],
      "source": [
        "# Specify some parameters\n",
        "learning_rate = 1e-4\n",
        "batch_size = 16\n",
        "epochs_number = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrB2XSFxRCL0",
        "outputId": "d190eded-8751-4838-f8a5-39421c384c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 5679\n",
            "Validation set size: 1135\n",
            "Test set size: 758\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the dataset\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/RNSA_Subset_PNGs_12K'\n",
        "\n",
        "# Get a list of all the folders in the dataset directory\n",
        "folders = [os.path.join(dataset_path, folder_name) for folder_name in os.listdir(dataset_path)]\n",
        "\n",
        "# Initialize empty lists to store the file paths for each set\n",
        "train_set, validation_set, test_set = [], [], []\n",
        "\n",
        "# Loop over each folder and split the PNG images into sets\n",
        "for folder in folders:\n",
        "    # Get the folder name (label)\n",
        "    folder_name = os.path.basename(folder)\n",
        "    # Get a list of all the PNG images in the folder\n",
        "    png_images = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.png')]\n",
        "    random.shuffle(png_images)\n",
        "    # Define the percentage split for train, validation, and test sets\n",
        "    train_percent, validation_percent, test_percent = 0.75, 0.15, 0.10\n",
        "    # Split the PNG images into train, validation, and test sets\n",
        "    num_files = len(png_images)\n",
        "    train_end = int(num_files * train_percent)\n",
        "    validation_end = int(num_files * (train_percent + validation_percent))\n",
        "    train_set += png_images[:train_end]\n",
        "    validation_set += png_images[train_end:validation_end]\n",
        "    test_set += png_images[validation_end:]\n",
        "\n",
        "\n",
        "# Create train, validation, and testing directories\n",
        "for directory in ['Train', 'Validation', 'Test']:\n",
        "    os.makedirs(os.path.join(dataset_path, directory), exist_ok=True)\n",
        "\n",
        "\n",
        "# Loop over the train, validation, and test sets, and copy each image to the appropriate directory\n",
        "for set_name, set_files in [('Train', train_set), ('Validation', validation_set), ('Test', test_set)]:\n",
        "    for folder_name in ['Normal', 'Any','EDH', 'SDH', 'SAH', 'IPH', 'IVH']:\n",
        "        # Create the folder in the set directory\n",
        "        os.makedirs(os.path.join(dataset_path, set_name, folder_name), exist_ok=True)\n",
        "        # Get the images in the current folder\n",
        "        folder_files = [f for f in set_files if folder_name in f]\n",
        "        # Copy the images to the set directory\n",
        "        for f in folder_files:\n",
        "            dest_folder = os.path.join(dataset_path, set_name, folder_name)\n",
        "            shutil.copy(f, dest_folder)\n",
        "\n",
        "# Print the number of images in each set\n",
        "print(\"Train set size:\", len(train_set))\n",
        "print(\"Validation set size:\", len(validation_set))\n",
        "print(\"Test set size:\", len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ZFNet architecture\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Convolutional layer 1\n",
        "    Conv2D(filters=96, kernel_size=(7, 7), strides=(2, 2), activation='relu', input_shape=(256, 256, 3)),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    # Convolutional layer 2\n",
        "    Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    # Convolutional layer 3\n",
        "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
        "    # Convolutional layer 4\n",
        "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
        "    # Convolutional layer 5\n",
        "    Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    # Flatten the output from convolutional layers\n",
        "    Flatten(),\n",
        "    # Fully-connected layer 1\n",
        "    Dense(units=4096, activation='relu'),\n",
        "    # Fully-connected layer 2\n",
        "    Dense(units=4096, activation='relu'),\n",
        "    # Output layer with 7 classes\n",
        "    Dense(units=7, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Eo1o7fLPxtpB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = Adam(learning_rate = learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# View the structure of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u05FgkJQ2Jnp",
        "outputId": "1bd78dd0-aaf5-472f-ebd6-b8d16ce0e609"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 125, 125, 96)      14208     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 62, 62, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              9441280   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 28679     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,977,735\n",
            "Trainable params: 29,977,735\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8tsOznxtF_59"
      },
      "outputs": [],
      "source": [
        "# Dataset Normalization\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, horizontal_flip = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A_D5vEbGJ5x",
        "outputId": "a43f8ab2-6c0b-4438-f03e-0e4eef4f8c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5679 images belonging to 7 classes.\n",
            "Found 1135 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "train_data = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/RNSA_Subset_PNGs_12K/Train', \n",
        "                                               target_size = (256, 256), \n",
        "                                               batch_size = batch_size, \n",
        "                                               class_mode = 'categorical')\n",
        "validation_data = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/RNSA_Subset_PNGs_12K/Validation', \n",
        "                                                    target_size = (256, 256), \n",
        "                                                    batch_size = batch_size, \n",
        "                                                    class_mode = 'categorical')\n",
        "#test_data = test_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/RNSA_Subset_PNGs_12K/Test', \n",
        "                                              #target_size = (256, 256), \n",
        "                                              #batch_size = batch_size, \n",
        "                                              #class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XfFb8ksaGWgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1158fcce-05f5-4918-b115-6003362f40ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "355/355 [==============================] - 36s 75ms/step - loss: 1.8825 - accuracy: 0.2210 - val_loss: 1.8381 - val_accuracy: 0.2529\n",
            "Epoch 2/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 1.8212 - accuracy: 0.2500 - val_loss: 1.7995 - val_accuracy: 0.2581\n",
            "Epoch 3/100\n",
            "355/355 [==============================] - 27s 75ms/step - loss: 1.7779 - accuracy: 0.2823 - val_loss: 1.7669 - val_accuracy: 0.2811\n",
            "Epoch 4/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 1.7224 - accuracy: 0.3108 - val_loss: 1.7532 - val_accuracy: 0.2943\n",
            "Epoch 5/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 1.6745 - accuracy: 0.3372 - val_loss: 1.7483 - val_accuracy: 0.3075\n",
            "Epoch 6/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 1.6193 - accuracy: 0.3599 - val_loss: 1.7161 - val_accuracy: 0.3436\n",
            "Epoch 7/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 1.5508 - accuracy: 0.3969 - val_loss: 1.7312 - val_accuracy: 0.3436\n",
            "Epoch 8/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 1.4776 - accuracy: 0.4237 - val_loss: 1.7891 - val_accuracy: 0.3084\n",
            "Epoch 9/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 1.3875 - accuracy: 0.4529 - val_loss: 1.7700 - val_accuracy: 0.3577\n",
            "Epoch 10/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 1.2821 - accuracy: 0.4934 - val_loss: 1.8303 - val_accuracy: 0.3463\n",
            "Epoch 11/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 1.1911 - accuracy: 0.5351 - val_loss: 1.9352 - val_accuracy: 0.3181\n",
            "Epoch 12/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 1.0895 - accuracy: 0.5742 - val_loss: 1.9636 - val_accuracy: 0.3251\n",
            "Epoch 13/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.9967 - accuracy: 0.6035 - val_loss: 2.0638 - val_accuracy: 0.3101\n",
            "Epoch 14/100\n",
            "355/355 [==============================] - 27s 75ms/step - loss: 0.9011 - accuracy: 0.6397 - val_loss: 2.1955 - val_accuracy: 0.3057\n",
            "Epoch 15/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.8320 - accuracy: 0.6683 - val_loss: 2.3871 - val_accuracy: 0.3154\n",
            "Epoch 16/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.7610 - accuracy: 0.6964 - val_loss: 2.4771 - val_accuracy: 0.2811\n",
            "Epoch 17/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.6920 - accuracy: 0.7066 - val_loss: 2.6138 - val_accuracy: 0.2890\n",
            "Epoch 18/100\n",
            "355/355 [==============================] - 27s 75ms/step - loss: 0.6454 - accuracy: 0.7257 - val_loss: 2.6586 - val_accuracy: 0.2802\n",
            "Epoch 19/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.6114 - accuracy: 0.7371 - val_loss: 2.7907 - val_accuracy: 0.2555\n",
            "Epoch 20/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.5654 - accuracy: 0.7445 - val_loss: 2.7958 - val_accuracy: 0.2458\n",
            "Epoch 21/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.5371 - accuracy: 0.7533 - val_loss: 2.9666 - val_accuracy: 0.2687\n",
            "Epoch 22/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 0.5053 - accuracy: 0.7551 - val_loss: 2.9873 - val_accuracy: 0.2617\n",
            "Epoch 23/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.4810 - accuracy: 0.7605 - val_loss: 3.1397 - val_accuracy: 0.2740\n",
            "Epoch 24/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.4668 - accuracy: 0.7649 - val_loss: 2.9523 - val_accuracy: 0.2537\n",
            "Epoch 25/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.4431 - accuracy: 0.7628 - val_loss: 3.4033 - val_accuracy: 0.2687\n",
            "Epoch 26/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.4341 - accuracy: 0.7574 - val_loss: 3.5102 - val_accuracy: 0.2652\n",
            "Epoch 27/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.4054 - accuracy: 0.7581 - val_loss: 3.4297 - val_accuracy: 0.2705\n",
            "Epoch 28/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.3940 - accuracy: 0.7665 - val_loss: 3.5145 - val_accuracy: 0.2811\n",
            "Epoch 29/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 0.3804 - accuracy: 0.7655 - val_loss: 3.9093 - val_accuracy: 0.2714\n",
            "Epoch 30/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 0.3928 - accuracy: 0.7628 - val_loss: 4.0838 - val_accuracy: 0.2573\n",
            "Epoch 31/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.4129 - accuracy: 0.7600 - val_loss: 4.0298 - val_accuracy: 0.2573\n",
            "Epoch 32/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.3601 - accuracy: 0.7684 - val_loss: 4.3768 - val_accuracy: 0.2678\n",
            "Epoch 33/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.3254 - accuracy: 0.7741 - val_loss: 4.1946 - val_accuracy: 0.2749\n",
            "Epoch 34/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.3133 - accuracy: 0.7790 - val_loss: 4.6378 - val_accuracy: 0.2643\n",
            "Epoch 35/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.3114 - accuracy: 0.7706 - val_loss: 4.5342 - val_accuracy: 0.2573\n",
            "Epoch 36/100\n",
            "355/355 [==============================] - 27s 76ms/step - loss: 0.3634 - accuracy: 0.7739 - val_loss: 4.4725 - val_accuracy: 0.2335\n",
            "Epoch 37/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.3900 - accuracy: 0.7651 - val_loss: 5.3507 - val_accuracy: 0.2573\n",
            "Epoch 38/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.3380 - accuracy: 0.7818 - val_loss: 5.3652 - val_accuracy: 0.2599\n",
            "Epoch 39/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.3155 - accuracy: 0.7808 - val_loss: 4.9325 - val_accuracy: 0.2767\n",
            "Epoch 40/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.2990 - accuracy: 0.7834 - val_loss: 5.0778 - val_accuracy: 0.2441\n",
            "Epoch 41/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.2918 - accuracy: 0.7801 - val_loss: 5.4258 - val_accuracy: 0.2617\n",
            "Epoch 42/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2897 - accuracy: 0.7839 - val_loss: 5.4054 - val_accuracy: 0.2520\n",
            "Epoch 43/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2919 - accuracy: 0.7915 - val_loss: 5.5611 - val_accuracy: 0.2423\n",
            "Epoch 44/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.4768 - accuracy: 0.7522 - val_loss: 4.8953 - val_accuracy: 0.2529\n",
            "Epoch 45/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.3302 - accuracy: 0.7868 - val_loss: 5.6980 - val_accuracy: 0.2652\n",
            "Epoch 46/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2988 - accuracy: 0.7920 - val_loss: 5.4514 - val_accuracy: 0.2467\n",
            "Epoch 47/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2864 - accuracy: 0.7980 - val_loss: 5.8903 - val_accuracy: 0.2643\n",
            "Epoch 48/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2972 - accuracy: 0.7959 - val_loss: 5.6191 - val_accuracy: 0.2652\n",
            "Epoch 49/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.3000 - accuracy: 0.7929 - val_loss: 6.0840 - val_accuracy: 0.2599\n",
            "Epoch 50/100\n",
            "355/355 [==============================] - 25s 69ms/step - loss: 0.3023 - accuracy: 0.7950 - val_loss: 4.9390 - val_accuracy: 0.2467\n",
            "Epoch 51/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.4120 - accuracy: 0.7658 - val_loss: 5.8902 - val_accuracy: 0.2511\n",
            "Epoch 52/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.3136 - accuracy: 0.7880 - val_loss: 6.3017 - val_accuracy: 0.2423\n",
            "Epoch 53/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2945 - accuracy: 0.7912 - val_loss: 5.7641 - val_accuracy: 0.2414\n",
            "Epoch 54/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2898 - accuracy: 0.7949 - val_loss: 6.4571 - val_accuracy: 0.2441\n",
            "Epoch 55/100\n",
            "355/355 [==============================] - 27s 75ms/step - loss: 0.2922 - accuracy: 0.7915 - val_loss: 6.2390 - val_accuracy: 0.2529\n",
            "Epoch 56/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 0.3815 - accuracy: 0.7771 - val_loss: 6.3626 - val_accuracy: 0.2555\n",
            "Epoch 57/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.3125 - accuracy: 0.7822 - val_loss: 6.3471 - val_accuracy: 0.2529\n",
            "Epoch 58/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2952 - accuracy: 0.7975 - val_loss: 5.3985 - val_accuracy: 0.2405\n",
            "Epoch 59/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.3110 - accuracy: 0.7942 - val_loss: 6.6003 - val_accuracy: 0.2493\n",
            "Epoch 60/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.3085 - accuracy: 0.7943 - val_loss: 6.5646 - val_accuracy: 0.2696\n",
            "Epoch 61/100\n",
            "355/355 [==============================] - 25s 69ms/step - loss: 0.3271 - accuracy: 0.7961 - val_loss: 6.1752 - val_accuracy: 0.2432\n",
            "Epoch 62/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.3043 - accuracy: 0.7924 - val_loss: 6.3437 - val_accuracy: 0.2564\n",
            "Epoch 63/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.2862 - accuracy: 0.8024 - val_loss: 7.1019 - val_accuracy: 0.2546\n",
            "Epoch 64/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2836 - accuracy: 0.8035 - val_loss: 6.6650 - val_accuracy: 0.2634\n",
            "Epoch 65/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2808 - accuracy: 0.8024 - val_loss: 6.1929 - val_accuracy: 0.2537\n",
            "Epoch 66/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.2783 - accuracy: 0.7987 - val_loss: 6.4642 - val_accuracy: 0.2581\n",
            "Epoch 67/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2749 - accuracy: 0.8075 - val_loss: 6.5027 - val_accuracy: 0.2678\n",
            "Epoch 68/100\n",
            "355/355 [==============================] - 24s 68ms/step - loss: 0.2793 - accuracy: 0.7996 - val_loss: 6.2324 - val_accuracy: 0.2449\n",
            "Epoch 69/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.4599 - accuracy: 0.7600 - val_loss: 6.1819 - val_accuracy: 0.2599\n",
            "Epoch 70/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.3183 - accuracy: 0.7922 - val_loss: 5.7278 - val_accuracy: 0.2608\n",
            "Epoch 71/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.3228 - accuracy: 0.7896 - val_loss: 6.4115 - val_accuracy: 0.2573\n",
            "Epoch 72/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2888 - accuracy: 0.8088 - val_loss: 6.5110 - val_accuracy: 0.2634\n",
            "Epoch 73/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2790 - accuracy: 0.8031 - val_loss: 6.8745 - val_accuracy: 0.2608\n",
            "Epoch 74/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2743 - accuracy: 0.8030 - val_loss: 6.8617 - val_accuracy: 0.2652\n",
            "Epoch 75/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.2742 - accuracy: 0.8054 - val_loss: 6.7547 - val_accuracy: 0.2722\n",
            "Epoch 76/100\n",
            "355/355 [==============================] - 24s 68ms/step - loss: 0.2733 - accuracy: 0.8017 - val_loss: 6.7353 - val_accuracy: 0.2643\n",
            "Epoch 77/100\n",
            "355/355 [==============================] - 25s 69ms/step - loss: 0.2733 - accuracy: 0.8089 - val_loss: 6.5423 - val_accuracy: 0.2687\n",
            "Epoch 78/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2735 - accuracy: 0.8098 - val_loss: 6.4516 - val_accuracy: 0.2696\n",
            "Epoch 79/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2735 - accuracy: 0.8045 - val_loss: 6.7935 - val_accuracy: 0.2643\n",
            "Epoch 80/100\n",
            "355/355 [==============================] - 26s 73ms/step - loss: 0.4179 - accuracy: 0.7714 - val_loss: 6.3191 - val_accuracy: 0.2687\n",
            "Epoch 81/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.3645 - accuracy: 0.7815 - val_loss: 6.6660 - val_accuracy: 0.2441\n",
            "Epoch 82/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.3033 - accuracy: 0.8061 - val_loss: 6.4542 - val_accuracy: 0.2731\n",
            "Epoch 83/100\n",
            "355/355 [==============================] - 25s 69ms/step - loss: 0.2926 - accuracy: 0.8067 - val_loss: 7.2895 - val_accuracy: 0.2652\n",
            "Epoch 84/100\n",
            "355/355 [==============================] - 25s 72ms/step - loss: 0.2908 - accuracy: 0.8030 - val_loss: 7.7821 - val_accuracy: 0.2626\n",
            "Epoch 85/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.2919 - accuracy: 0.8024 - val_loss: 7.1092 - val_accuracy: 0.2555\n",
            "Epoch 86/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.2816 - accuracy: 0.8100 - val_loss: 6.6293 - val_accuracy: 0.2678\n",
            "Epoch 87/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2758 - accuracy: 0.8144 - val_loss: 7.2468 - val_accuracy: 0.2599\n",
            "Epoch 88/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2733 - accuracy: 0.8125 - val_loss: 7.1058 - val_accuracy: 0.2599\n",
            "Epoch 89/100\n",
            "355/355 [==============================] - 26s 74ms/step - loss: 0.2735 - accuracy: 0.8044 - val_loss: 6.8054 - val_accuracy: 0.2643\n",
            "Epoch 90/100\n",
            "355/355 [==============================] - 25s 69ms/step - loss: 0.2733 - accuracy: 0.8037 - val_loss: 6.8933 - val_accuracy: 0.2634\n",
            "Epoch 91/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 0.2731 - accuracy: 0.8084 - val_loss: 6.9650 - val_accuracy: 0.2537\n",
            "Epoch 92/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.2735 - accuracy: 0.8045 - val_loss: 6.8466 - val_accuracy: 0.2581\n",
            "Epoch 93/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.4473 - accuracy: 0.7655 - val_loss: 6.0684 - val_accuracy: 0.2643\n",
            "Epoch 94/100\n",
            "355/355 [==============================] - 25s 69ms/step - loss: 0.3233 - accuracy: 0.7929 - val_loss: 6.4412 - val_accuracy: 0.2441\n",
            "Epoch 95/100\n",
            "355/355 [==============================] - 25s 71ms/step - loss: 0.2939 - accuracy: 0.8010 - val_loss: 6.2167 - val_accuracy: 0.2511\n",
            "Epoch 96/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 0.2835 - accuracy: 0.8026 - val_loss: 7.4132 - val_accuracy: 0.2722\n",
            "Epoch 97/100\n",
            "355/355 [==============================] - 26s 72ms/step - loss: 0.3417 - accuracy: 0.7896 - val_loss: 7.5735 - val_accuracy: 0.2564\n",
            "Epoch 98/100\n",
            "355/355 [==============================] - 24s 68ms/step - loss: 0.3244 - accuracy: 0.8005 - val_loss: 8.2358 - val_accuracy: 0.2828\n",
            "Epoch 99/100\n",
            "355/355 [==============================] - 25s 70ms/step - loss: 0.2861 - accuracy: 0.8135 - val_loss: 7.3839 - val_accuracy: 0.2749\n",
            "Epoch 100/100\n",
            "355/355 [==============================] - 25s 72ms/step - loss: 0.2830 - accuracy: 0.8158 - val_loss: 8.0179 - val_accuracy: 0.2767\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "res_history = model.fit(train_data, \n",
        "                        validation_data = validation_data, \n",
        "                        epochs = epochs_number, \n",
        "                        steps_per_epoch = len(train_data), \n",
        "                        validation_steps = len(validation_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vbuN1zkGbpU"
      },
      "outputs": [],
      "source": [
        "# Plot the loss\n",
        "plt.plot(res_history.history['loss'], label='Train Loss')\n",
        "plt.plot(res_history.history['val_loss'], label='Validation Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.axes().set(xlabel='Epoch', ylabel='Loss', title='Architecture Loss');\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# Plot the accuracy\n",
        "plt.plot(res_history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(res_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.axes().set(xlabel='Epoch', ylabel='Accuracy', title='Architecture Accuracy');\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}